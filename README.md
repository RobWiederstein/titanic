# Kaggle Competition: Predicting Who Survived the Titanic

## What is Kaggle?

I'd never heard of Kaggle before my Coursera Machine Learning Course.  Kaggle is a forum for people and organizations to post data challenges and compete, sometimes for money, for the best score.  Mathematical models are trained using different algorithms on the "training" data and then applied to the "testing" data.  The Kaggle Titanic Challenge was considered to be an introductory challenge.  At last check, there were over 6,000 teams vying for the top spot. The deadline for the competition is December 31, 2016.

## Competition Description

The folks at Kaggle provided the following background for the competition.  The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.

One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.

In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.

## Attribution Warranted

For my first Kaggle competition, I thought I was doing pretty well, but as the deadline approached I had fallen to 61st percentile. Still, I'm pretty happy about the outcome.  However, my efforts were largely the result of the many folks that submitted kernels and provided other resources on the internet.

- First, a huge shout out to Megan Risdale at [Kaggle](https://www.kaggle.com/mrisdal) for getting me started with an excellent kernel.

- Second, I burned up Jason Brownlee's website [Machine Learning Mastery](http://machinelearningmastery.com/start-here/).  While I haven't bought his [book](https://machinelearningmastery.com/machine-learning-with-r/) yet, I intend to.

- Third, the person who made the modeling in R easier is Max Kuhn, the author of R's `caret` package.  His [website](http://topepo.github.io/caret/index.html) and book [Applied Predictive Modeling](http://appliedpredictivemodeling.com) provided invaluable assistance in improving the models.

- Fourth, Professors Jeff Leek, Roger Peng, and Brian Caffo at the Bloomberg School of Health provided inspiration via their Coursera [course](https://www.coursera.org/specializations/jhu-data-science).

- Fifth, there were dozens of others.  If I omitted you, I apologize.  Your willingness to share information on the web made me --and no doubt many others-- more effective.  Thank you.
